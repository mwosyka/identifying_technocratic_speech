{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmzRG+uzVvAV4ac+Moovni"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "_M586POXImBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "import spacy\n",
        "!pip install -U sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "nlp.max_length = 20000000"
      ],
      "metadata": {
        "id": "Z1b4tAvMIlO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing and Splitting Large Text Corpus into Sentences"
      ],
      "metadata": {
        "id": "v1C-elCCIrEw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7fOsj2KyAyu"
      },
      "outputs": [],
      "source": [
        "with open('/content/Scraped_Articles_Large_Text_Corpus', 'r', encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "    sentences_articles = f.read()\n",
        "about_doc = nlp(sentences_articles)\n",
        "unclean_sentences = list(about_doc.sents) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAEyauaJBdTs"
      },
      "outputs": [],
      "source": [
        "sentences = [x for x in unclean_sentences if len (x) > 2]\n",
        "sentences[:10]\n",
        "sorted(sentences, key=len)\n",
        "len(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform Sentences into Vectors"
      ],
      "metadata": {
        "id": "NeUz-RH_JmVu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hacoo4jx035b"
      },
      "outputs": [],
      "source": [
        "embedder = SentenceTransformer('all-mpnet-base-v2')\n",
        "corpus = sentences\n",
        "corpus_embeddings = embedder.encode(corpus, show_progress_bar=True, batch_size = 64)\n",
        "print(corpus_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insert Anchor Sentences"
      ],
      "metadata": {
        "id": "ruKAEBMDJpsN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpBSQHr_VKwJ"
      },
      "outputs": [],
      "source": [
        "queries = [\"This is a technocratic anchor sentence\", \\\n",
        "           \"This is another technocratic anchor sentence\",\\\n",
        "           \"This is a third technocratic anchor sentence\",\\\n",
        "           ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rx-og3e7VLbc"
      },
      "outputs": [],
      "source": [
        "top_k =min(10, len(corpus))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding 10 Most Semantically Similar Sentences in Large Text Corpus for Each Anchor Sentence"
      ],
      "metadata": {
        "id": "6nCFXJntKinL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mzl9uQwFVPwV"
      },
      "outputs": [],
      "source": [
        "for query in queries:\n",
        "  query_embedding = embedder.encode(query, convert_to_tensor = True)\n",
        "  cos_scores = util.cos_sim(query_embedding, corpus_embeddings) [0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  print(\"\\n\\nQuery ==> \", query)\n",
        "  print('-----------------------------------------------')\n",
        "\n",
        "  for score, idx in zip(top_results[0], top_results[1]) :\n",
        "    print(corpus[idx], \"(Score: (:.4f))\".format(score))"
      ]
    }
  ]
}