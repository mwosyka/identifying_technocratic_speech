{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOq0HqiJeJIPo89200w/O/b"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "Vek-IGrq6kBm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-G9GsZVR8MP"
      },
      "outputs": [],
      "source": [
        "! pip install -q pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njnugWjEoomi"
      },
      "outputs": [],
      "source": [
        "! pip install -q bs4\n",
        "! pip install -q transformers\n",
        "! pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAPrAV09o9vg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "import transformers\n",
        "from transformers import BertModel,BertTokenizer,AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import torch\n",
        "from torch import nn ,cuda\n",
        "from torch.utils.data import DataLoader,Dataset,RandomSampler, SequentialSampler\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPMW3mTYpEhK"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "%matplotlib inline\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Data"
      ],
      "metadata": {
        "id": "PPb5PRNp6qak"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGqJgnjGyAnw"
      },
      "outputs": [],
      "source": [
        "df_content = pd.read_excel(\"/content/TRAINING_SENTENCES_CONTENT.xlsx\")\n",
        "\n",
        "df_cat = pd.read_excel(\"/content/TRAINING_SENTENCES_TAGS.xlsx\")\n",
        "\n",
        "pment_prelim = pd.read_excel(\"/content/PARLIAMENT_PROTOCOL_CORPUS.xlsx\")\n",
        "\n",
        "questions = pment_prelim['text']\n",
        "word_cnt = [len(quest.split()) for quest in questions]\n",
        "\n",
        "plt.figure(figsize=[8,5])\n",
        "plt.hist(word_cnt, bins = 10)\n",
        "plt.xlabel('Word Count/Question')\n",
        "plt.ylabel('# of Occurences')\n",
        "plt.title(\"Frequency of Word Counts/sentence\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning"
      ],
      "metadata": {
        "id": "DnFfBT8n6t45"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pu6I57zpISxb"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "nlp.max_length = 20000000\n",
        "EIN_SATZ=\"yes\"\n",
        "print(EIN_SATZ)\n",
        "if EIN_SATZ==\"no\":\n",
        "    pment=pment_prelim\n",
        "else: \n",
        "    pment.drop(pment.index[:], inplace=True)\n",
        "    item=1\n",
        "    wortlimit=3\n",
        "    for iter in range(len(pment_prelim)):\n",
        "      about_doc = nlp(pment_prelim.loc[iter,\"text\" ])\n",
        "      for sent in about_doc.sents:\n",
        "        if (str(sent) != \" \") & (len(sent)>wortlimit):\n",
        "          pment=pment.append({'id':item, 'text':str(sent)}, ignore_index = True)\n",
        "          item +=1\n",
        "    print(pment.loc[0, \"text\"])\n",
        "    file_name = \"/content/Test_eng.xlsx\" \n",
        "    pment.to_excel(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcuznGWwP7eq"
      },
      "outputs": [],
      "source": [
        "def pre_process(text):\n",
        "  \n",
        "  text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
        "  text = text.lower()\n",
        "  tokens = text.split()\n",
        "  text= text.encode('ascii', 'ignore').decode()\n",
        "  text= re.sub(r'https*\\S+', ' ', text)\n",
        "  text= re.sub(r'http*\\S+', ' ',text)\n",
        "  text= re.sub(r'\\'\\w+', '',text) \n",
        "  text= re.sub(r'\\w*\\d+\\w*', '',text)\n",
        "  text= re.sub(r'\\s{2,}', ' ',text)\n",
        "  text= re.sub(r'\\s[^\\w\\s]\\s', '',text)\n",
        "  return text\n",
        "df_content['Content_clean'] = df_content['Content'].apply(pre_process)\n",
        "pment['text_clean'] = pment['text'].apply(pre_process)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialising BERT"
      ],
      "metadata": {
        "id": "ILegoC1J6ydB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkDtCy0LUeWc"
      },
      "outputs": [],
      "source": [
        "BERT_MODEL_NAME = \"bert-base-cased\"\n",
        "Bert_tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qobAkrNZp1S9"
      },
      "outputs": [],
      "source": [
        "print(df_content.head(2))\n",
        "df_content.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VabLO2JdgbNT"
      },
      "outputs": [],
      "source": [
        "df_cat_grouped = df_cat.groupby('Line').apply(lambda x:x['Tag'].values).reset_index(name='tags')\n",
        "df_cat_grouped.sample (3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSywBifzXngl"
      },
      "outputs": [],
      "source": [
        "df_calc = pd.merge(df_content,df_cat_grouped,how='inner',on='Line')\n",
        "print(df_calc.sample(3))\n",
        "df_calc.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlPbct4kgsBZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "yt = mlb.fit_transform(df_calc['tags'])\n",
        "print(yt)\n",
        "yt.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0mgCI62072K"
      },
      "outputs": [],
      "source": [
        "print(yt[0])\n",
        "print(mlb.inverse_transform(yt[0].reshape(1,-1)))\n",
        "print(mlb.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekzzP8C3W-kI"
      },
      "outputs": [],
      "source": [
        "x = df_calc['Content_clean'].tolist()\n",
        "len(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting Model Data in Training and Test Data"
      ],
      "metadata": {
        "id": "d0rYu9Nq62gt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoI5254djbCN"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x, yt, test_size=0.1, random_state=RANDOM_SEED,shuffle=True)\n",
        "x_tr,x_val,y_tr,y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=RANDOM_SEED,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIPlZeVfjkCx"
      },
      "outputs": [],
      "source": [
        "len(x_tr) ,len(x_val), len(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Training"
      ],
      "metadata": {
        "id": "gmYsniqV7CEm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3M22L5qjsio"
      },
      "outputs": [],
      "source": [
        "class QTagDataset (Dataset):\n",
        "    def __init__(self,quest,tags, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.text = quest\n",
        "        self.labels = tags\n",
        "        self.max_len = max_len\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "    \n",
        "    def __getitem__(self, item_idx):\n",
        "        text = self.text[item_idx]\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length= self.max_len,\n",
        "            padding = 'max_length',\n",
        "            return_token_type_ids= False,\n",
        "            return_attention_mask= True,\n",
        "            truncation=True,\n",
        "            return_tensors = 'pt'\n",
        "          )\n",
        "        input_ids = inputs['input_ids'].flatten()\n",
        "        attn_mask = inputs['attention_mask'].flatten()\n",
        "        return {\n",
        "            'input_ids': input_ids ,\n",
        "            'attention_mask': attn_mask,\n",
        "            'label': torch.tensor(self.labels[item_idx], dtype=torch.float)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxZ-ZJT6jwtw"
      },
      "outputs": [],
      "source": [
        "class QTagDataModule (pl.LightningDataModule):\n",
        "    \n",
        "    def __init__(self,x_tr,y_tr,x_val,y_val,x_test,y_test,tokenizer,batch_size=16,max_token_len=200):\n",
        "        super().__init__()\n",
        "        self.tr_text = x_tr\n",
        "        self.tr_label = y_tr\n",
        "        self.val_text = x_val\n",
        "        self.val_label = y_val\n",
        "        self.test_text = x_test\n",
        "        self.test_label = y_test\n",
        "        self.tokenizer = tokenizer\n",
        "        self.batch_size = batch_size\n",
        "        self.max_token_len = max_token_len\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        self.train_dataset = QTagDataset(quest=self.tr_text, tags=self.tr_label, tokenizer=self.tokenizer,max_len = self.max_token_len)\n",
        "        self.val_dataset  = QTagDataset(quest=self.val_text,tags=self.val_label,tokenizer=self.tokenizer,max_len = self.max_token_len)\n",
        "        self.test_dataset  = QTagDataset(quest=self.test_text,tags=self.test_label,tokenizer=self.tokenizer,max_len = self.max_token_len)\n",
        "        \n",
        "        \n",
        "    def train_dataloader(self):\n",
        "        return DataLoader (self.train_dataset,batch_size = self.batch_size,shuffle = True , num_workers=2)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader (self.val_dataset,batch_size= 16)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader (self.test_dataset,batch_size= 16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALNRbIjXj7c9"
      },
      "outputs": [],
      "source": [
        "max_word_cnt = 300\n",
        "quest_cnt = 0\n",
        "for question in x:\n",
        "    input_ids = Bert_tokenizer.encode(question, add_special_tokens=True)\n",
        "    if len(input_ids) > max_word_cnt:\n",
        "        quest_cnt +=1\n",
        "print(f'# Question having word count > {max_word_cnt}: is  {quest_cnt}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioI2SZ_8kxsn"
      },
      "outputs": [],
      "source": [
        "N_EPOCHS = 12\n",
        "BATCH_SIZE = 32\n",
        "MAX_LEN = 300\n",
        "LR = 2e-05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8iDg-grk2V8"
      },
      "outputs": [],
      "source": [
        "QTdata_module = QTagDataModule(x_tr,y_tr,x_val,y_val,x_test,y_test,Bert_tokenizer,BATCH_SIZE,MAX_LEN)\n",
        "QTdata_module.setup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1NN_0TCk8_M"
      },
      "outputs": [],
      "source": [
        "class QTagClassifier(pl.LightningModule):\n",
        "    def __init__(self, n_classes=5, steps_per_epoch=None, n_epochs=3, lr=2e-5 ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size,n_classes)\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "        self.n_epochs = n_epochs\n",
        "        self.lr = lr\n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "        \n",
        "    def forward(self,input_ids, attn_mask):\n",
        "        output = self.bert(input_ids = input_ids ,attention_mask = attn_mask)\n",
        "        output = self.classifier(output.pooler_output)\n",
        "                \n",
        "        return output\n",
        "    \n",
        "    \n",
        "    def training_step(self,batch,batch_idx):\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        labels = batch['label']\n",
        "        \n",
        "        outputs = self(input_ids,attention_mask)\n",
        "        loss = self.criterion(outputs,labels)\n",
        "        self.log('train_loss',loss , prog_bar=True,logger=True)\n",
        "        \n",
        "        return {\"loss\" :loss, \"predictions\":outputs, \"labels\": labels }\n",
        "\n",
        "\n",
        "    def validation_step(self,batch,batch_idx):\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        labels = batch['label']\n",
        "        \n",
        "        outputs = self(input_ids,attention_mask)\n",
        "        loss = self.criterion(outputs,labels)\n",
        "        self.log('val_loss',loss , prog_bar=True,logger=True)\n",
        "        \n",
        "        return loss\n",
        "\n",
        "    def test_step(self,batch,batch_idx):\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        labels = batch['label']\n",
        "        \n",
        "        outputs = self(input_ids,attention_mask)\n",
        "        loss = self.criterion(outputs,labels)\n",
        "        self.log('test_loss',loss , prog_bar=True,logger=True)\n",
        "        \n",
        "        return loss\n",
        "    \n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        optimizer = AdamW(self.parameters() , lr=self.lr)\n",
        "        warmup_steps = self.steps_per_epoch//3\n",
        "        total_steps = self.steps_per_epoch * self.n_epochs - warmup_steps\n",
        "\n",
        "        scheduler = get_linear_schedule_with_warmup(optimizer,warmup_steps,total_steps)\n",
        "\n",
        "        return [optimizer], [scheduler]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StJyiG4QlA0v"
      },
      "outputs": [],
      "source": [
        "steps_per_epoch = len(x_tr)//BATCH_SIZE\n",
        "model = QTagClassifier(n_classes=5, steps_per_epoch=steps_per_epoch,n_epochs=N_EPOCHS,lr=LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8OeO6DDlEXh"
      },
      "outputs": [],
      "source": [
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor='val_loss',\n",
        "    filename='QTag-{epoch:02d}-{val_loss:.2f}',\n",
        "    save_top_k=3,\n",
        "    mode='min',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHxI7n8ZlN5D"
      },
      "outputs": [],
      "source": [
        "trainer = pl.Trainer(max_epochs = N_EPOCHS , accelerator=\"gpu\", callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7m3YOz2m945"
      },
      "outputs": [],
      "source": [
        "trainer.fit(model, QTdata_module)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLnUOpg1mcUD"
      },
      "outputs": [],
      "source": [
        "model_path = checkpoint_callback.best_model_path\n",
        "model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQO77XJwmhk3"
      },
      "outputs": [],
      "source": [
        "len(y_test), len(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCrcKtqGml58"
      },
      "outputs": [],
      "source": [
        "print(f'Number of Questions = {len(x_test)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iryQVoIrmobm"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "\n",
        "for quest in x_test:\n",
        "    encoded_quest =  Bert_tokenizer.encode_plus(\n",
        "                    quest,\n",
        "                    None,\n",
        "                    add_special_tokens=True,\n",
        "                    max_length= MAX_LEN,\n",
        "                    padding = 'max_length',\n",
        "                    return_token_type_ids= False,\n",
        "                    return_attention_mask= True,\n",
        "                    truncation=True,\n",
        "                    return_tensors = 'pt'      \n",
        "    )   \n",
        "    input_ids.append(encoded_quest['input_ids'])\n",
        "    attention_masks.append(encoded_quest['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(y_test)\n",
        "TEST_BATCH_SIZE = 64  \n",
        "\n",
        "pred_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "pred_sampler = SequentialSampler(pred_data)\n",
        "pred_dataloader = DataLoader(pred_data, sampler=pred_sampler, batch_size=TEST_BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8UZllMkmtTE"
      },
      "outputs": [],
      "source": [
        "flat_pred_outs = 0\n",
        "flat_true_labels = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyYDA47LmxNp"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "pred_outs, true_labels = [], [] \n",
        "for batch in pred_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_attn_mask, b_labels = batch\n",
        " \n",
        "    with torch.no_grad():\n",
        "        pred_out = model(b_input_ids,b_attn_mask)\n",
        "        pred_out = torch.sigmoid(pred_out)\n",
        "        pred_out = pred_out.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "    pred_outs.append(pred_out)\n",
        "    true_labels.append(label_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgkZh4Yvm0sL"
      },
      "outputs": [],
      "source": [
        "pred_outs[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVnk2giEm2Xy"
      },
      "outputs": [],
      "source": [
        "flat_pred_outs = np.concatenate(pred_outs, axis=0)\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3unOm84vm32c"
      },
      "outputs": [],
      "source": [
        "flat_pred_outs.shape , flat_true_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fstqnx3fniHG"
      },
      "outputs": [],
      "source": [
        "flat_pred_outs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfDlRVS_nwRN"
      },
      "outputs": [],
      "source": [
        "threshold  = np.arange(0.4,0.51,0.01)\n",
        "threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZJsoG6Kn0Tq"
      },
      "outputs": [],
      "source": [
        "def classify(pred_prob,thresh):\n",
        "    y_pred = []\n",
        "\n",
        "    for tag_label_row in pred_prob:\n",
        "        temp=[]\n",
        "        for tag_label in tag_label_row:\n",
        "            if tag_label >= thresh:\n",
        "                temp.append(1)\n",
        "            else:\n",
        "                temp.append(0)\n",
        "        y_pred.append(temp)\n",
        "\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "196YW37Xn4nh"
      },
      "outputs": [],
      "source": [
        "flat_pred_outs[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTymyqtVn7GA"
      },
      "outputs": [],
      "source": [
        "flat_true_labels[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPbwDKb5n9tR"
      },
      "outputs": [],
      "source": [
        "flat_pred_outs[5]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identifying Optimal Threshold Value"
      ],
      "metadata": {
        "id": "F28ad3DY7MHg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AS7_kRbuoEuQ"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "scores=[]\n",
        "\n",
        "y_true = flat_true_labels.ravel() \n",
        "\n",
        "for thresh in threshold:\n",
        "    \n",
        "    pred_bin_label = classify(flat_pred_outs,thresh) \n",
        "\n",
        "    y_pred = np.array(pred_bin_label).ravel()\n",
        "\n",
        "    scores.append(metrics.f1_score(y_true,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGppzTQ3oHXI"
      },
      "outputs": [],
      "source": [
        "opt_thresh = threshold[scores.index(max(scores))]\n",
        "print(f'Optimal Threshold Value = {opt_thresh}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og9_6LJloL76"
      },
      "outputs": [],
      "source": [
        "y_pred_labels = classify(flat_pred_outs,opt_thresh)\n",
        "y_pred = np.array(y_pred_labels).ravel()\n",
        "y_pred[90]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBpQ1klzoQbl"
      },
      "outputs": [],
      "source": [
        "print(metrics.classification_report(y_true,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DE--Fc_xoWbw"
      },
      "outputs": [],
      "source": [
        "y_pred = mlb.inverse_transform(np.array(y_pred_labels))\n",
        "y_act = mlb.inverse_transform(flat_true_labels)\n",
        "\n",
        "df_train = pd.DataFrame({'Body':x_test,'Actual Tags':y_act,'Predicted Tags':y_pred})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting Classifications of Test Data Set"
      ],
      "metadata": {
        "id": "cRMZAWoE8Y8E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7Us-mkRoanY"
      },
      "outputs": [],
      "source": [
        "df_train.sample(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLqky9k8p_Yn"
      },
      "outputs": [],
      "source": [
        "QTmodel = QTagClassifier.load_from_checkpoint(model_path)\n",
        "QTmodel.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting Classifications"
      ],
      "metadata": {
        "id": "fMkwlKNX7kaB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBSWvfp4qEq4"
      },
      "outputs": [],
      "source": [
        "def predict(question):\n",
        "    text_enc = Bert_tokenizer.encode_plus(\n",
        "            question,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length= MAX_LEN,\n",
        "            padding = 'max_length',\n",
        "            return_token_type_ids= False,\n",
        "            return_attention_mask= True,\n",
        "            truncation=True,\n",
        "            return_tensors = 'pt'      \n",
        "    )\n",
        "    outputs = QTmodel(text_enc['input_ids'], text_enc['attention_mask'])\n",
        "    pred_out = outputs[0].detach().numpy()\n",
        "    preds = [(pred > opt_thresh) for pred in pred_out ]\n",
        "    preds = np.asarray(preds)\n",
        "    new_preds = preds.reshape(1,-1).astype(int)\n",
        "    pred_tags = mlb.inverse_transform(new_preds)\n",
        "    return pred_tags"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysing and Predicting Large Text Corpus"
      ],
      "metadata": {
        "id": "L2naQe0u7pz5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VaEVOSdQcQ-s"
      },
      "outputs": [],
      "source": [
        "print(len(pment))\n",
        "\n",
        "for zeile in range (len(pment)):\n",
        "  tags=predict(pment.loc[zeile,\"text_clean\"])\n",
        "  if not tags[0]:\n",
        "    text=\"keineZuordnung\"\n",
        "    pment.loc[zeile, \"analyse\"]=text.split()\n",
        "  else:\n",
        "    pment.loc[zeile, \"analyse\"]=set(tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Pze49cMBiAQ5"
      },
      "outputs": [],
      "source": [
        "print(pment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OoiFfgU-eefY"
      },
      "outputs": [],
      "source": [
        "print(len(pment))\n",
        "\n",
        "for zeile in range (len(pment)):\n",
        "  tags=predict(pment.loc[zeile,\"text_clean\"])\n",
        "  if not tags[0]:\n",
        "    text=\"keineZuordnung\"\n",
        "    pment.loc[zeile, \"analyse\"]=text.split()\n",
        "  else:\n",
        "    pment.loc[zeile, \"analyse\"]=set(tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MvVnoh8NlHh0"
      },
      "outputs": [],
      "source": [
        " print(pment.sample(15))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excel-Output of Classified Text Units"
      ],
      "metadata": {
        "id": "Mf7ALfuu8EuA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jwETHUl-nQh9"
      },
      "outputs": [],
      "source": [
        "file_name = \"/content/Output_Parlament_eng_multi.xlsx\" \n",
        "pment.to_excel(file_name)"
      ]
    }
  ]
}